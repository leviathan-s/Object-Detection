{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ocpl04vTu55t"},"outputs":[],"source":["# mmcv 설치하기\n","!pip3 install openmim\n","!mim install mmcv-full"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSLTrTwmvC46"},"outputs":[],"source":["# mmdetection git clone\n","!git clone https://github.com/open-mmlab/mmdetection.git\n","%cd mmdetection\n","!pip install -e ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2117,"status":"ok","timestamp":1680181673354,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"},"user_tz":-540},"id":"1kWh0e0AvFTb","outputId":"ce060ecd-5e98-49c8-c932-21dd2d89e7e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.28.2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n"]}],"source":["import mmdet\n","import mmcv\n","print(mmdet.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6LhoXx4mtngj"},"outputs":[],"source":["# SMD Dataset Registry\n","from mmdet.datasets.builder import DATASETS\n","from mmdet.datasets.coco import CocoDataset\n","\n","@DATASETS.register_module(force=True)\n","class SMDDataset(CocoDataset):\n","  CLASSES = ('Ferry','Buoy', 'Vessel/ship', 'Speed boat','Boat','Kayak','Sail boat','Swimming person','Flying bird/plane','Other')"]},{"cell_type":"markdown","metadata":{"id":"qUZDuKMsxIYx"},"source":["DarkNet-53 backbone YOLOv3 Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZotJlhafWja"},"outputs":[],"source":["# Google Drive Mount\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"GZbBT_lDmLjP"},"source":["아래 셀에check pointfile의 경로를 내가 가장 최근까지 train시킨 가중치 파일로 교체한다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5emaQa9xPfa"},"outputs":[],"source":["# config file setting\n","config_file = './configs/yolo/yolov3_d53_mstrain-608_273e_coco.py'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11879,"status":"ok","timestamp":1679918084295,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"},"user_tz":-540},"id":"oqR1ZqlM4uxQ","outputId":"0b3a907a-fe16-40a0-d82c-9f871ca42a45"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-27 11:54:32--  https://download.openmmlab.com/mmdetection/v2.0/yolo/yolov3_d53_mstrain-608_273e_coco/yolov3_d53_mstrain-608_273e_coco_20210518_115020-a2c3acb8.pth\n","Resolving download.openmmlab.com (download.openmmlab.com)... 47.246.48.207, 47.246.48.204, 47.246.48.206, ...\n","Connecting to download.openmmlab.com (download.openmmlab.com)|47.246.48.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248093138 (237M) [application/octet-stream]\n","Saving to: ‘/content/mmdetection/checkpoints/yolov3_d53_mstrain-608_273e_coco_20210518_115020-a2c3acb8.pth’\n","\n","/content/mmdetectio 100%[===================>] 236.60M  26.0MB/s    in 10s     \n","\n","2023-03-27 11:54:43 (22.9 MB/s) - ‘/content/mmdetection/checkpoints/yolov3_d53_mstrain-608_273e_coco_20210518_115020-a2c3acb8.pth’ saved [248093138/248093138]\n","\n"]}],"source":["# YOLO v3 (DarkNet53) pretrained weight Model Download\n","!mkdir /content/mmdetection/checkpoints\n","!wget -O /content/mmdetection/checkpoints/yolov3_d53_mstrain-608_273e_coco_20210518_115020-a2c3acb8.pth https://download.openmmlab.com/mmdetection/v2.0/yolo/yolov3_d53_mstrain-608_273e_coco/yolov3_d53_mstrain-608_273e_coco_20210518_115020-a2c3acb8.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1680181713668,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"},"user_tz":-540},"id":"c6XEwVODxvPr","outputId":"87e43c1d-89ff-4d1d-cdab-e8298bf86962"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: './mmdetection'\n","/content/mmdetection\n","/content\n"]}],"source":["# Load YOLOv3 Config Object\n","from mmcv import Config\n","%cd ./mmdetection\n","cfg = Config.fromfile(config_file)\n","%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yeQGkd5P5sd"},"outputs":[],"source":["# Modify dataset type and path.\n","cfg.dataset_type = 'SMDDataset'\n","cfg.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","\n","cfg.data.test.type = 'SMDDataset'\n","cfg.data.test.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame/val.json'\n","cfg.data.test.ann_file = 'val.json'\n","cfg.data.test.img_prefix = 'val'\n","\n","cfg.data.train.type = 'SMDDataset'\n","cfg.data.train.ann_file = '/content/drive/MyDrive/SMDDataset/35_Frame/train.json'\n","cfg.data.train.img_prefix = '/content/drive/MyDrive/SMDDataset/35_Frame/train'\n","\n","cfg.data.val.type = 'SMDDataset'\n","cfg.data.val.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","cfg.data.val.ann_file = 'val.json'\n","cfg.data.val.img_prefix = 'val'\n","\n","# Batch size (samples per GPU).\n","cfg.data.samples_per_gpu = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-viAi60QzS1"},"outputs":[],"source":["# Modify number of classes as per the model head.\n","cfg.model.bbox_head.num_classes = 10\n"," \n","# model checkpoint path. \n","cfg.load_from = '/content/mmdetection/checkpoints/yolov3_d53_mstrain-608_273e_coco_20210518_115020-a2c3acb8.pth'\n","\n","# Learning Rate Setting\n","cfg.optimizer.lr = 0.001\n","cfg.log_config.interval = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYgZEaYSREF8"},"outputs":[],"source":["from mmdet.apis import set_random_seed\n","# The output directory for training. As per the model name.\n","cfg.work_dir = '/content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)'\n","\n","# Evaluation Metric > MS COCO Challenge\n","cfg.evaluation.metric = 'bbox'\n","cfg.evaluation.save_best = 'auto'\n","\n","# Evaluate every 5 training epochs\n","cfg.evaluation.interval = 5\n","\n","# Checkpoint storage interval.\n","cfg.checkpoint_config.interval = 48\n","\n","# Set random seed for reproducible results.\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","cfg.device = 'cuda' \n","\n","# Total epochs to train\n","cfg.runner.max_epochs = 210\n","\n","# Use tensorboard to log the training process\n","cfg.log_config.hooks = [\n","    dict(type='TextLoggerHook'),\n","    dict(type='TensorboardLoggerHook')]"]},{"cell_type":"code","source":["print('#'*50)\n","print(f'Config:\\n{cfg.pretty_text}')"],"metadata":{"id":"qOrFqc5A7JR3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680181715564,"user_tz":-540,"elapsed":1900,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"}},"outputId":"084c930a-5d82-48f4-9e91-64b636345000"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["##################################################\n","Config:\n","checkpoint_config = dict(interval=48)\n","log_config = dict(\n","    interval=50,\n","    hooks=[dict(type='TextLoggerHook'),\n","           dict(type='TensorboardLoggerHook')])\n","custom_hooks = [dict(type='NumClassCheckHook')]\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = '/content/mmdetection/checkpoints/yolov3_d53_mstrain-608_273e_coco_20210518_115020-a2c3acb8.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","opencv_num_threads = 0\n","mp_start_method = 'fork'\n","auto_scale_lr = dict(enable=False, base_batch_size=64)\n","model = dict(\n","    type='YOLOV3',\n","    backbone=dict(\n","        type='Darknet',\n","        depth=53,\n","        out_indices=(3, 4, 5),\n","        init_cfg=dict(type='Pretrained', checkpoint='open-mmlab://darknet53')),\n","    neck=dict(\n","        type='YOLOV3Neck',\n","        num_scales=3,\n","        in_channels=[1024, 512, 256],\n","        out_channels=[512, 256, 128]),\n","    bbox_head=dict(\n","        type='YOLOV3Head',\n","        num_classes=10,\n","        in_channels=[512, 256, 128],\n","        out_channels=[1024, 512, 256],\n","        anchor_generator=dict(\n","            type='YOLOAnchorGenerator',\n","            base_sizes=[[(116, 90), (156, 198), (373, 326)],\n","                        [(30, 61), (62, 45), (59, 119)],\n","                        [(10, 13), (16, 30), (33, 23)]],\n","            strides=[32, 16, 8]),\n","        bbox_coder=dict(type='YOLOBBoxCoder'),\n","        featmap_strides=[32, 16, 8],\n","        loss_cls=dict(\n","            type='CrossEntropyLoss',\n","            use_sigmoid=True,\n","            loss_weight=1.0,\n","            reduction='sum'),\n","        loss_conf=dict(\n","            type='CrossEntropyLoss',\n","            use_sigmoid=True,\n","            loss_weight=1.0,\n","            reduction='sum'),\n","        loss_xy=dict(\n","            type='CrossEntropyLoss',\n","            use_sigmoid=True,\n","            loss_weight=2.0,\n","            reduction='sum'),\n","        loss_wh=dict(type='MSELoss', loss_weight=2.0, reduction='sum')),\n","    train_cfg=dict(\n","        assigner=dict(\n","            type='GridAssigner',\n","            pos_iou_thr=0.5,\n","            neg_iou_thr=0.5,\n","            min_pos_iou=0)),\n","    test_cfg=dict(\n","        nms_pre=1000,\n","        min_bbox_size=0,\n","        score_thr=0.05,\n","        conf_thr=0.005,\n","        nms=dict(type='nms', iou_threshold=0.45),\n","        max_per_img=100))\n","dataset_type = 'SMDDataset'\n","data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","img_norm_cfg = dict(mean=[0, 0, 0], std=[255.0, 255.0, 255.0], to_rgb=True)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile', to_float32=True),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(type='Expand', mean=[0, 0, 0], to_rgb=True, ratio_range=(1, 2)),\n","    dict(\n","        type='MinIoURandomCrop',\n","        min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n","        min_crop_size=0.3),\n","    dict(type='Resize', img_scale=[(320, 320), (608, 608)], keep_ratio=True),\n","    dict(type='RandomFlip', flip_ratio=0.5),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(\n","        type='Normalize',\n","        mean=[0, 0, 0],\n","        std=[255.0, 255.0, 255.0],\n","        to_rgb=True),\n","    dict(type='Pad', size_divisor=32),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(608, 608),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[0, 0, 0],\n","                std=[255.0, 255.0, 255.0],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=2,\n","    workers_per_gpu=4,\n","    train=dict(\n","        type='SMDDataset',\n","        ann_file='/content/drive/MyDrive/SMDDataset/35_Frame/train.json',\n","        img_prefix='/content/drive/MyDrive/SMDDataset/35_Frame/train',\n","        pipeline=[\n","            dict(type='LoadImageFromFile', to_float32=True),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(\n","                type='Expand', mean=[0, 0, 0], to_rgb=True,\n","                ratio_range=(1, 2)),\n","            dict(\n","                type='MinIoURandomCrop',\n","                min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n","                min_crop_size=0.3),\n","            dict(\n","                type='Resize',\n","                img_scale=[(320, 320), (608, 608)],\n","                keep_ratio=True),\n","            dict(type='RandomFlip', flip_ratio=0.5),\n","            dict(type='PhotoMetricDistortion'),\n","            dict(\n","                type='Normalize',\n","                mean=[0, 0, 0],\n","                std=[255.0, 255.0, 255.0],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","        ]),\n","    val=dict(\n","        type='SMDDataset',\n","        ann_file='val.json',\n","        img_prefix='val',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(608, 608),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[0, 0, 0],\n","                        std=[255.0, 255.0, 255.0],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        data_root='/content/drive/MyDrive/SMDDataset/35_Frame'),\n","    test=dict(\n","        type='SMDDataset',\n","        ann_file='val.json',\n","        img_prefix='val',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(608, 608),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[0, 0, 0],\n","                        std=[255.0, 255.0, 255.0],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        data_root='/content/drive/MyDrive/SMDDataset/35_Frame/val.json'))\n","optimizer = dict(\n","    type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005, nesterov=True)\n","optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n","lr_config = dict(\n","    policy='step',\n","    warmup='linear',\n","    warmup_iters=2000,\n","    warmup_ratio=0.1,\n","    step=[218, 246])\n","runner = dict(type='EpochBasedRunner', max_epochs=210)\n","evaluation = dict(interval=5, metric='bbox', save_best='auto')\n","work_dir = '/content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)'\n","seed = 0\n","gpu_ids = range(0, 1)\n","device = 'cuda'\n","\n"]}]},{"cell_type":"code","source":["# learning rate decay : Cosine Annealing\n","cfg.lr_config.policy = 'CosineAnnealing'\n","\n","# Limitation on learning rate\n","cfg.lr_config.min_lr_ratio = 0.01\n","by_epoch = False\n","del(cfg.lr_config.step)"],"metadata":{"id":"JrSN1H7HQV5-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1891,"status":"ok","timestamp":1679924861792,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"},"user_tz":-540},"id":"CBWU_2yLRWRN","outputId":"1e3e76b2-e31a-48fb-d733-7a439240fa02"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n"]}],"source":["from mmdet.datasets import build_dataset\n","from mmdet.models import build_detector\n","from mmdet.apis import train_detector\n","\n","import os.path as osp\n","import mmcv\n","# Build dataset\n","datasets = [build_dataset(cfg.data.train)]\n","# Build the detector\n","model = build_detector(cfg.model)\n","# Add an attribute for visualization convenience\n","model.CLASSES = datasets[0].CLASSES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xG6ooA0GDhVW"},"outputs":[],"source":["# Create work_dir\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","# Start Training\n","train_detector(model, datasets, cfg, distributed=False, validate=True)"]},{"cell_type":"markdown","metadata":{"id":"jnY0UxSzFHzG"},"source":["여기서부터는 **Inference code**입니다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vt7mEZ2lD9l2"},"outputs":[],"source":["from mmdet.apis import inference_detector\n","from mmdet.apis import init_detector\n","from mmcv import Config\n","import argparse\n","import mmcv\n","import glob as glob\n","import os\n","\n","# load config, weights\n","config_file = './configs/yolo/yolov3_d53_mstrain-608_273e_coco.py'\n","weights = '/content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)/YOLOv3_final.pth'\n","cfg = Config.fromfile(config_file)\n","\n","# video file path for inference\n","video_inputs = [\\\n","    \"/content/drive/MyDrive/test_images/test_video.mp4\"]\n","\n","video_outputs = [\\\n","    \"/content/drive/MyDrive/Model_Weight(SMD)/YOLOx/result/test_video_result.mp4\"]\n","\n","# confidence-theshold for inference\n","threshold = 0.5"]},{"cell_type":"code","source":["# Reset config and rebuild model\n","# Modify dataset type and path.\n","cfg.dataset_type = 'SMDDataset'\n","cfg.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","\n","cfg.data.test.type = 'SMDDataset'\n","cfg.data.test.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","cfg.data.test.ann_file = 'val.json'\n","cfg.data.test.img_prefix = 'val'\n","\n","cfg.data.train.type = 'SMDDataset'\n","cfg.data.train.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","cfg.data.train.ann_file = 'train.json'\n","cfg.data.train.img_prefix = 'train'\n","\n","cfg.data.val.type = 'SMDDataset'\n","cfg.data.val.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","cfg.data.val.ann_file = 'val.json'\n","cfg.data.val.img_prefix = 'val'\n","\n","# Batch size (samples per GPU).\n","cfg.data.samples_per_gpu = 1\n","\n","# Modify number of classes as per the model head.\n","cfg.model.bbox_head.num_classes = 10\n","\n","from mmdet.apis import set_random_seed\n","# The output directory for training. As per the model name.\n","cfg.work_dir = '/content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)'\n","\n","# Evaluation Metric.\n","cfg.evaluation.metric = 'bbox'\n","cfg.evaluation.save_best = 'auto'\n","\n","\n","# Set random seed for reproducible results.\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","cfg.device = 'cuda' \n","\n","\n","# Use tensorboard to log the training process\n","cfg.log_config.hooks = [\n","    dict(type='TextLoggerHook'),\n","    dict(type='TensorboardLoggerHook')]\n","\n","# Build the model.\n","model = init_detector(cfg, weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBxcZVARA_kl","executionInfo":{"status":"ok","timestamp":1680058370392,"user_tz":-540,"elapsed":11226,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"}},"outputId":"0b644064-6dfb-4f05-a59f-263d4d1c1056"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["load checkpoint from local path: /content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)/YOLOv3_final.pth\n"]}]},{"cell_type":"code","source":["# Start Image file inference\n","\n","# Classes for SMD Dataset \n","labels_to_names_seq = {0:'Ferry',1:'Buoy',2:'Vessel/Ship',3:'Speed boat',4:'Boat',5:'Kayak',6:'Sail boat',7:'Swimming person',8:'Flying bird/plane',9:'Other'}\n","\n","labels_to_names = {0:'Ferry',1:'Buoy',2:'Vessel/Ship',3:'Speed boat',4:'Boat',5:'Kayak',6:'Sail boat',7:'Swimming person',8:'Flying bird/plane',9:'Other'}\n","\n","# Function for visualization of inference result\n","def get_detected_img(model, img_array,  score_threshold=0.45, is_print=True):\n","  # 인자로 들어온 image_array를 복사. \n","  draw_img = img_array.copy()\n","  bbox_color=(0, 255, 0) # bbox는 Green색으로 표시한다\n","  text_color=(0, 0, 255) # text는 Red색으로 표시한다\n","\n","  results = inference_detector(model, img_array)\n","\n","\n","  for result_ind, result in enumerate(results):\n","    if len(result) == 0:\n","      continue\n","     \n","    result_filtered = result[np.where(result[:, 4] > score_threshold)]\n","    \n","    # confidence score가 threshold 이상으로 탐지된 object에 대하여 표시한다\n","    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출. \n","    for i in range(len(result_filtered)):\n","      # 좌상단, 우하단 좌표 추출. \n","      left = int(result_filtered[i, 0])\n","      top = int(result_filtered[i, 1])\n","      right = int(result_filtered[i, 2])\n","      bottom = int(result_filtered[i, 3])\n","      caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], result_filtered[i, 4]) # Bounding Box위에 표시할 caption\n","      cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=3)\n","      cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)\n","      if is_print:\n","        print(caption)\n","\n","  return draw_img #  bounding box와 caption이 표시된 image를 반환한다"],"metadata":{"id":"Uei3NNraBEkV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import os\n","\n","input_images = [file for file in os.listdir(\"/content/drive/MyDrive/test_images\") if file.split(\".\")[1] == \"jpg\" or file.split(\".\")[1] == \"JPG\"]\n","# JPG 또는 jpg파일만 inference시행\n","\n","for input_image in input_images:\n","  output_image = \"/content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)/result/\" + input_image[:-5] + \"_result.jpg\"\n","  input_image = \"/content/drive/MyDrive/test_images/\" + input_image\n","  img_arr = cv2.imread(input_image)\n","  detected_img = get_detected_img(model, img_arr,  score_threshold=0.45, is_print=False)\n","  cv2.imwrite(output_image, detected_img)"],"metadata":{"id":"k6PckWTdSIeW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start Video Inference\n","import argparse\n","import mmcv\n","import time\n","import cv2\n","\n","for i in range(len(video_inputs)):\n","  input_video = video_inputs[i]\n","  output_video = video_outputs[i]\n","\n","  cap = mmcv.VideoReader(input_video)\n","  save_name = output_video\n","  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","  \n","  out = cv2.VideoWriter(\n","      save_name, fourcc, cap.fps,\n","      (cap.width, cap.height)\n","  )\n","  frame_count = 0 # To count total frames.\n","  total_fps = 0 # To get the final frames per second.\n","\n","  for frame in mmcv.track_iter_progress(cap):\n","      # Increment frame count.\n","      frame_count += 1\n","      start_time = time.time()# Forward pass start time.\n","      result = inference_detector(model, frame)\n","      end_time = time.time() # Forward pass end time.\n","      # Get the fps.\n","      fps = 1 / (end_time - start_time)\n","      # Add fps to total fps.\n","      total_fps += fps\n","      show_result = model.show_result(frame, result, score_thr=threshold)\n","      # Write the FPS on the current frame.\n","      cv2.putText(\n","          show_result, f\"{fps:.3f} FPS\", (15, 30), cv2.FONT_HERSHEY_SIMPLEX,\n","          1, (0, 0, 255), 2, cv2.LINE_AA\n","      )\n","      # mmcv.imshow(show_result, 'Result', wait_time=1)\n","      out.write(show_result)\n","  # Release VideoCapture()\n","  out.release()\n","  # Close all frames and video windows\n","  cv2.destroyAllWindows()\n","  # Calculate and print the average FPS\n","  avg_fps = total_fps / frame_count\n","  print(f\"Average FPS: {avg_fps:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"El3X2xltM39f","executionInfo":{"status":"ok","timestamp":1680058496060,"user_tz":-540,"elapsed":47109,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"}},"outputId":"5e0a8c55-e87c-450a-ac67-d635a798f196"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 184/184, 4.0 task/s, elapsed: 46s, ETA:     0s\n","Average FPS: 17.579\n"]}]},{"cell_type":"markdown","source":["***Performance Evaluation***\n","\n","아래 셀을 수행하기 전 런타임 재시작을 하지 않으면 버그 발생 (Key error)"],"metadata":{"id":"TAtpz65-iUFI"}},{"cell_type":"code","source":["from mmdet.apis import inference_detector\n","from mmdet.apis import init_detector\n","from mmcv import Config\n","import argparse\n","import mmcv\n","import glob as glob\n","import os\n","\n","config_file = '/content/mmdetection/configs/yolo/yolov3_d53_mstrain-608_273e_coco.py'\n","checkpoint_file = '/content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)/YOLOv3_final.pth'\n","cfg = Config.fromfile(config_file)\n","\n","from mmcv import Config\n","from mmdet.datasets.builder import DATASETS\n","from mmdet.datasets.coco import CocoDataset\n","from mmdet.apis import set_random_seed\n","\n","# Dataset re-registry\n","@DATASETS.register_module(force=True)\n","class SMDDataset(CocoDataset):\n","  CLASSES = ('Ferry','Buoy', 'Vessel/ship', 'Speed boat','Boat','Kayak','Sail boat','Swimming person','Flying bird/plane','Other')\n","\n","# Reset config and rebuild model\n","# Modify dataset type and path.\n","cfg.dataset_type = 'SMDDataset'\n","cfg.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","\n","cfg.data.test.type = 'SMDDataset'\n","cfg.data.test.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","cfg.data.test.ann_file = 'val.json'\n","cfg.data.test.img_prefix = 'val'\n","\n","cfg.data.train.type = 'SMDDataset'\n","cfg.data.train.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","cfg.data.train.ann_file = 'train.json'\n","cfg.data.train.img_prefix = 'train'\n","\n","cfg.data.val.type = 'SMDDataset'\n","cfg.data.val.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n","cfg.data.val.ann_file = 'val.json'\n","cfg.data.val.img_prefix = 'val'\n","\n","# Batch size (samples per GPU).\n","cfg.data.samples_per_gpu = 1\n","\n","# Modify number of classes as per the model head.\n","cfg.model.bbox_head.num_classes = 10\n","\n","from mmdet.apis import set_random_seed\n","# The output directory for training. As per the model name.\n","cfg.work_dir = '/content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)'\n","\n","# Evaluation Metric.\n","cfg.evaluation.metric = 'bbox'\n","cfg.evaluation.save_best = 'auto'\n","\n","# Set random seed for reproducible results.\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","cfg.device = 'cuda' \n","\n","\n","cfg.log_config.hooks = [\n","    dict(type='TextLoggerHook'),\n","    dict(type='TensorboardLoggerHook')]\n","\n","cfg.evaluation.classwise = True"],"metadata":{"id":"J1aFNqstiTct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mmdet.datasets import (build_dataloader, build_dataset,replace_ImageToTensor)\n","\n","# test용 Dataset과 DataLoader 생성. \n","# build_dataset()호출 시 list로 감싸지 않는 것이 train용 dataset 생성시와 차이\n","# train용 dataset는 list로 감싸야 하고, test용 dataset는 list로 감싸지 않는다\n","dataset = build_dataset(cfg.data.test) # test dataset을 만든다\n","data_loader = build_dataloader(\n","        dataset,\n","        # 반드시 아래 samples_per_gpu 인자값은 1로 설정\n","        samples_per_gpu=cfg.data.samples_per_gpu, # 그래서 아까 config설정할 때 이 값을 1로 설정한 것이다\n","        workers_per_gpu=cfg.data.workers_per_gpu,\n","        dist=False,\n","        shuffle=False)\n","\n","# \n","next(iter(data_loader))"],"metadata":{"id":"P3jeM7QGiesk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"285rLw2DiyOV","executionInfo":{"status":"ok","timestamp":1680058729117,"user_tz":-540,"elapsed":4547,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"}},"outputId":"c5720b2d-066f-4284-93d9-a9e0766ac66e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["load checkpoint from local path: /content/drive/MyDrive/Model_Weight(SMD)/YOLOv3(DarkNet_53)/YOLOv3_final.pth\n"]}]},{"cell_type":"code","source":["from mmdet.apis import multi_gpu_test, single_gpu_test\n","from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n","from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n","\n","model_ckpt = MMDataParallel(model_ckpt, device_ids=[0]) # 병렬처리를 하기 위한 코드드\n","\n","outputs = single_gpu_test(model_ckpt, data_loader, True, '/content', 0.3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzbQhQmXi3ss","executionInfo":{"status":"ok","timestamp":1680058797646,"user_tz":-540,"elapsed":56111,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"}},"outputId":"111a4671-f4fd-44e5-bab8-4caa6b2c9b0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 113/113, 2.0 task/s, elapsed: 56s, ETA:     0s"]}]},{"cell_type":"code","source":["# evaluation실시\n","metric = dataset.evaluate(outputs, metric='bbox', classwise = True)\n","print(metric)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4M3ZEWxCjDM6","executionInfo":{"status":"ok","timestamp":1680058798290,"user_tz":-540,"elapsed":651,"user":{"displayName":"_96 Blackjack","userId":"18351879974904137523"}},"outputId":"e8122fa3-7374-472c-ca5b-68408ac19b29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Evaluating bbox...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.21s).\n","Accumulating evaluation results...\n","DONE (t=0.08s).\n","\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.747\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.447\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.317\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.443\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.506\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.504\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.504\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.354\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.483\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.554\n","\n","\n","+------------+-------+-----------------+-------+-------------------+-------+\n","| category   | AP    | category        | AP    | category          | AP    |\n","+------------+-------+-----------------+-------+-------------------+-------+\n","| Ferry      | 0.323 | Buoy            | 0.480 | Vessel/ship       | 0.542 |\n","| Speed boat | 0.434 | Boat            | 0.247 | Kayak             | nan   |\n","| Sail boat  | 0.833 | Swimming person | nan   | Flying bird/plane | 0.331 |\n","| Other      | 0.367 | None            | None  | None              | None  |\n","+------------+-------+-----------------+-------+-------------------+-------+\n","OrderedDict([('bbox_mAP', 0.4447), ('bbox_mAP_50', 0.7475), ('bbox_mAP_75', 0.4469), ('bbox_mAP_s', 0.3169), ('bbox_mAP_m', 0.4435), ('bbox_mAP_l', 0.5064), ('bbox_mAP_copypaste', '0.4447 0.7475 0.4469 0.3169 0.4435 0.5064')])\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/tilemmpon/Singapore-Maritime-Dataset-Frames-Ground-Truth-Generation-and-Statistics/blob/master/Singapore_dataset_frames_generation_and_histograms.ipynb","timestamp":1677762677298}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}