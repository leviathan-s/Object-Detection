{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocpl04vTu55t"
      },
      "outputs": [],
      "source": [
        "# mmcv 설치하기\n",
        "!pip3 install openmim\n",
        "!mim install mmcv-full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSLTrTwmvC46"
      },
      "outputs": [],
      "source": [
        "# mmdetection git clone\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kWh0e0AvFTb"
      },
      "outputs": [],
      "source": [
        "import mmdet\n",
        "import mmcv\n",
        "print(mmdet.__version__)\n",
        "# Example output: 2.23.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LhoXx4mtngj"
      },
      "outputs": [],
      "source": [
        "# SMD Dataset Registry\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.coco import CocoDataset\n",
        "\n",
        "@DATASETS.register_module(force=True)\n",
        "class SMDDataset(CocoDataset):\n",
        "  CLASSES = ('Ferry','Buoy', 'Vessel/ship', 'Speed boat','Boat','Kayak','Sail boat','Swimming person','Flying bird/plane','Other')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUZDuKMsxIYx"
      },
      "source": [
        "SSD Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZotJlhafWja",
        "outputId": "0a1fda49-c01d-4490-a35f-ab5c637d6945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZbBT_lDmLjP"
      },
      "source": [
        "아래 셀에check pointfile의 경로를 내가 가장 최근까지 train시킨 가중치 파일로 교체한다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5emaQa9xPfa"
      },
      "outputs": [],
      "source": [
        "# config file setting\n",
        "config_file = '/content/mmdetection/configs/ssd/ssd300_coco.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqR1ZqlM4uxQ",
        "outputId": "cf25ea38-e1ee-41f2-fc5f-f010f9bbcbc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-26 12:48:29--  https://download.openmmlab.com/mmdetection/v2.0/ssd/ssd300_coco/ssd300_coco_20210803_015428-d231a06e.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 8.48.85.210, 8.48.85.214, 8.48.85.213, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|8.48.85.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137242646 (131M) [application/octet-stream]\n",
            "Saving to: ‘/content/mmdetection/checkpoints/ssd300_coco_20210803_015428-d231a06e.pth’\n",
            "\n",
            "/content/mmdetectio 100%[===================>] 130.88M  24.8MB/s    in 5.4s    \n",
            "\n",
            "2023-03-26 12:48:34 (24.3 MB/s) - ‘/content/mmdetection/checkpoints/ssd300_coco_20210803_015428-d231a06e.pth’ saved [137242646/137242646]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SSD pretrained weight Model Download\n",
        "!mkdir /content/mmdetection/checkpoints\n",
        "!wget -O /content/mmdetection/checkpoints/ssd300_coco_20210803_015428-d231a06e.pth https://download.openmmlab.com/mmdetection/v2.0/ssd/ssd300_coco/ssd300_coco_20210803_015428-d231a06e.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6XEwVODxvPr",
        "outputId": "cd9999fe-3eb4-45cf-8caa-a5008d4b1357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmdetection\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Load SSD Config Object\n",
        "from mmcv import Config\n",
        "%cd ./mmdetection\n",
        "cfg = Config.fromfile(config_file)\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yeQGkd5P5sd"
      },
      "outputs": [],
      "source": [
        "# Modify dataset type and path.\n",
        "cfg.dataset_type = 'SMDDataset'\n",
        "cfg.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "\n",
        "cfg.data.test.type = 'SMDDataset'\n",
        "cfg.data.test.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame/val.json'\n",
        "cfg.data.test.ann_file = 'val.json'\n",
        "cfg.data.test.img_prefix = 'val'\n",
        "\n",
        "cfg.data.train.dataset.type = 'SMDDataset'\n",
        "cfg.data.train.dataset.ann_file = '/content/drive/MyDrive/SMDDataset/35_Frame/train.json'\n",
        "cfg.data.train.dataset.img_prefix = '/content/drive/MyDrive/SMDDataset/35_Frame/train'\n",
        "\n",
        "cfg.data.val.type = 'SMDDataset'\n",
        "cfg.data.val.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "cfg.data.val.ann_file = 'val.json'\n",
        "cfg.data.val.img_prefix = 'val'\n",
        "\n",
        "# Batch size (samples per GPU).\n",
        "cfg.data.samples_per_gpu = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-viAi60QzS1"
      },
      "outputs": [],
      "source": [
        "# Modify number of classes as per the model head.\n",
        "cfg.model.bbox_head.num_classes = 10\n",
        "\n",
        "# model checkpoint path. \n",
        "cfg.load_from = '/content/mmdetection/checkpoints/ssd300_coco_20210803_015428-d231a06e.pth'\n",
        "\n",
        "# Learning Rate Setting\n",
        "cfg.optimizer.lr = 0.001\n",
        "cfg.log_config.interval = 50 # 몇 개 사진을 train할때마다 log를 띄울 것인가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYgZEaYSREF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b20291-8076-488b-d9b0-1cdc488a7571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################################################\n",
            "Config:\n",
            "input_size = 300\n",
            "model = dict(\n",
            "    type='SingleStageDetector',\n",
            "    backbone=dict(\n",
            "        type='SSDVGG',\n",
            "        depth=16,\n",
            "        with_last_pool=False,\n",
            "        ceil_mode=True,\n",
            "        out_indices=(3, 4),\n",
            "        out_feature_indices=(22, 34),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained', checkpoint='open-mmlab://vgg16_caffe')),\n",
            "    neck=dict(\n",
            "        type='SSDNeck',\n",
            "        in_channels=(512, 1024),\n",
            "        out_channels=(512, 1024, 512, 256, 256, 256),\n",
            "        level_strides=(2, 2, 1, 1),\n",
            "        level_paddings=(1, 1, 0, 0),\n",
            "        l2_norm_scale=20),\n",
            "    bbox_head=dict(\n",
            "        type='SSDHead',\n",
            "        in_channels=(512, 1024, 512, 256, 256, 256),\n",
            "        num_classes=10,\n",
            "        anchor_generator=dict(\n",
            "            type='SSDAnchorGenerator',\n",
            "            scale_major=False,\n",
            "            input_size=300,\n",
            "            basesize_ratio_range=(0.15, 0.9),\n",
            "            strides=[8, 16, 32, 64, 100, 300],\n",
            "            ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[0.1, 0.1, 0.2, 0.2])),\n",
            "    train_cfg=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.5,\n",
            "            neg_iou_thr=0.5,\n",
            "            min_pos_iou=0.0,\n",
            "            ignore_iof_thr=-1,\n",
            "            gt_max_assign_all=False),\n",
            "        smoothl1_beta=1.0,\n",
            "        allowed_border=-1,\n",
            "        pos_weight=-1,\n",
            "        neg_pos_ratio=3,\n",
            "        debug=False),\n",
            "    test_cfg=dict(\n",
            "        nms_pre=1000,\n",
            "        nms=dict(type='nms', iou_threshold=0.45),\n",
            "        min_bbox_size=0,\n",
            "        score_thr=0.02,\n",
            "        max_per_img=200))\n",
            "cudnn_benchmark = True\n",
            "dataset_type = 'SMDDataset'\n",
            "data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
            "img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[1, 1, 1], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        type='Expand',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        to_rgb=True,\n",
            "        ratio_range=(1, 4)),\n",
            "    dict(\n",
            "        type='MinIoURandomCrop',\n",
            "        min_ious=(0.1, 0.3, 0.5, 0.7, 0.9),\n",
            "        min_crop_size=0.3),\n",
            "    dict(type='Resize', img_scale=(300, 300), keep_ratio=False),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='PhotoMetricDistortion',\n",
            "        brightness_delta=32,\n",
            "        contrast_range=(0.5, 1.5),\n",
            "        saturation_range=(0.5, 1.5),\n",
            "        hue_delta=18),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[1, 1, 1],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(300, 300),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=False),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[1, 1, 1],\n",
            "                to_rgb=True),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=3,\n",
            "    train=dict(\n",
            "        type='RepeatDataset',\n",
            "        times=5,\n",
            "        dataset=dict(\n",
            "            type='SMDDataset',\n",
            "            ann_file='/content/drive/MyDrive/SMDDataset/35_Frame/train.json',\n",
            "            img_prefix='/content/drive/MyDrive/SMDDataset/35_Frame/train',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations', with_bbox=True),\n",
            "                dict(\n",
            "                    type='Expand',\n",
            "                    mean=[123.675, 116.28, 103.53],\n",
            "                    to_rgb=True,\n",
            "                    ratio_range=(1, 4)),\n",
            "                dict(\n",
            "                    type='MinIoURandomCrop',\n",
            "                    min_ious=(0.1, 0.3, 0.5, 0.7, 0.9),\n",
            "                    min_crop_size=0.3),\n",
            "                dict(type='Resize', img_scale=(300, 300), keep_ratio=False),\n",
            "                dict(type='RandomFlip', flip_ratio=0.5),\n",
            "                dict(\n",
            "                    type='PhotoMetricDistortion',\n",
            "                    brightness_delta=32,\n",
            "                    contrast_range=(0.5, 1.5),\n",
            "                    saturation_range=(0.5, 1.5),\n",
            "                    hue_delta=18),\n",
            "                dict(\n",
            "                    type='Normalize',\n",
            "                    mean=[123.675, 116.28, 103.53],\n",
            "                    std=[1, 1, 1],\n",
            "                    to_rgb=True),\n",
            "                dict(type='DefaultFormatBundle'),\n",
            "                dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "            ])),\n",
            "    val=dict(\n",
            "        type='SMDDataset',\n",
            "        ann_file='val.json',\n",
            "        img_prefix='val',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(300, 300),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=False),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[1, 1, 1],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        data_root='/content/drive/MyDrive/SMDDataset/35_Frame'),\n",
            "    test=dict(\n",
            "        type='SMDDataset',\n",
            "        ann_file='val.json',\n",
            "        img_prefix='val',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(300, 300),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=False),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[1, 1, 1],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        data_root='/content/drive/MyDrive/SMDDataset/35_Frame/val.json'))\n",
            "evaluation = dict(interval=3, metric='bbox', save_best='auto')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
            "optimizer_config = dict()\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[16, 22])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=210)\n",
            "checkpoint_config = dict(interval=48)\n",
            "log_config = dict(\n",
            "    interval=50,\n",
            "    hooks=[dict(type='TextLoggerHook'),\n",
            "           dict(type='TensorboardLoggerHook')])\n",
            "custom_hooks = [\n",
            "    dict(type='NumClassCheckHook'),\n",
            "    dict(type='CheckInvalidLossHook', interval=50, priority='VERY_LOW')\n",
            "]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = '/content/mmdetection/checkpoints/ssd300_coco_20210803_015428-d231a06e.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=64)\n",
            "work_dir = '/content/drive/MyDrive/Model_Weight(SMD)/ssd'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "device = 'cuda'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "# The output directory for training. As per the model name.\n",
        "cfg.work_dir = '/content/drive/MyDrive/Model_Weight(SMD)/ssd'\n",
        "\n",
        "# Evaluation Metric > MS COCO Challenge\n",
        "cfg.evaluation.metric = 'bbox'\n",
        "cfg.evaluation.save_best = 'auto'\n",
        "\n",
        "# Evaluate every 5 training epochs\n",
        "cfg.evaluation.interval = 3\n",
        "\n",
        "# Checkpoint storage interval.\n",
        "cfg.checkpoint_config.interval = 48\n",
        "\n",
        "# Set random seed for reproducible results.\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.device = 'cuda' \n",
        "\n",
        "# Total epochs to train\n",
        "cfg.runner.max_epochs = 210\n",
        "\n",
        "# Use tensorboard to log the training process\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "print('#'*50)\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb7jUslkNKeL"
      },
      "outputs": [],
      "source": [
        "# learning rate decay : Cosine Annealing\n",
        "cfg.lr_config.policy = 'CosineAnnealing'\n",
        "\n",
        "# Limitation on learning rate\n",
        "cfg.lr_config.min_lr_ratio = 0.05\n",
        "cfg.by_epoch = False\n",
        "del(cfg.lr_config.step)\n",
        "cfg.data.train.times = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBWU_2yLRWRN",
        "outputId": "048b33bd-8767-4330-de61-af4640a8d569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.13s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "import os.path as osp\n",
        "import mmcv\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "# Build the detector\n",
        "model = build_detector(cfg.model)\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG6ooA0GDhVW"
      },
      "outputs": [],
      "source": [
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "# Start Training\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnY0UxSzFHzG"
      },
      "source": [
        "여기서부터는 **Inference code**입니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt7mEZ2lD9l2"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import inference_detector\n",
        "from mmdet.apis import init_detector\n",
        "from mmcv import Config\n",
        "import argparse\n",
        "import mmcv\n",
        "import glob as glob\n",
        "import os\n",
        "config_file = '/content/mmdetection/configs/ssd/ssd300_coco.py'\n",
        "weights = '/content/drive/MyDrive/Model_Weight(SMD)/ssd/ssd_final_weight.pth'\n",
        "cfg = Config.fromfile(config_file)\n",
        "\n",
        "video_inputs = [\\\n",
        "    \"/content/drive/MyDrive/test_images/test_video.mp4\"]\n",
        "\n",
        "video_outputs = [\\\n",
        "    \"/content/drive/MyDrive/Model_Weight(SMD)/ssd/result/test_video_result.mp4\"]\n",
        "\n",
        "threshold = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset config and rebuild model\n",
        "# Modify dataset type and path.\n",
        "cfg.dataset_type = 'SMDDataset'\n",
        "cfg.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "\n",
        "cfg.data.test.type = 'SMDDataset'\n",
        "cfg.data.test.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "cfg.data.test.ann_file = 'val.json'\n",
        "cfg.data.test.img_prefix = 'val'\n",
        "\n",
        "cfg.data.train.type = 'SMDDataset'\n",
        "cfg.data.train.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "cfg.data.train.ann_file = 'train.json'\n",
        "cfg.data.train.img_prefix = 'train'\n",
        "\n",
        "cfg.data.val.type = 'SMDDataset'\n",
        "cfg.data.val.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "cfg.data.val.ann_file = 'val.json'\n",
        "cfg.data.val.img_prefix = 'val'\n",
        "\n",
        "# Batch size (samples per GPU).\n",
        "cfg.data.samples_per_gpu = 1\n",
        "\n",
        "# Modify number of classes as per the model head.\n",
        "cfg.model.bbox_head.num_classes = 10\n",
        "\n",
        "from mmdet.apis import set_random_seed\n",
        "# The output directory for training. As per the model name.\n",
        "cfg.work_dir = '/content/drive/MyDrive/Model_Weight(SMD)/ssd'\n",
        "\n",
        "# Evaluation Metric.\n",
        "cfg.evaluation.metric = 'bbox'\n",
        "cfg.evaluation.save_best = 'auto'\n",
        "\n",
        "# Set random seed for reproducible results.\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.device = 'cuda' \n",
        "\n",
        "\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "model = init_detector(cfg, weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBxcZVARA_kl",
        "outputId": "da3b770e-bce9-4cb6-eaa6-18c294151572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from local path: /content/drive/MyDrive/Model_Weight(SMD)/ssd/ssd_final_weight.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Image file inference\n",
        "\n",
        "# Classes for SMD Dataset  \n",
        "labels_to_names_seq = {0:'Ferry',1:'Buoy',2:'Vessel/Ship',3:'Speed boat',4:'Boat',5:'Kayak',6:'Sail boat',7:'Swimming person',8:'Flying bird/plane',9:'Other'}\n",
        "\n",
        "labels_to_names = {0:'Ferry',1:'Buoy',2:'Vessel/Ship',3:'Speed boat',4:'Boat',5:'Kayak',6:'Sail boat',7:'Swimming person',8:'Flying bird/plane',9:'Other'}\n",
        "\n",
        "# Function for visualization of inference result\n",
        "def get_detected_img(model, img_array,  score_threshold=0.45, is_print=True):\n",
        "  # 인자로 들어온 image_array를 복사. \n",
        "  draw_img = img_array.copy()\n",
        "  bbox_color=(0, 255, 0) # bbox는 Green색으로 표시한다\n",
        "  text_color=(0, 0, 255) # text는 Red색으로 표시한다\n",
        "\n",
        "  results = inference_detector(model, img_array)\n",
        "\n",
        "\n",
        "  for result_ind, result in enumerate(results):\n",
        "    if len(result) == 0:\n",
        "      continue\n",
        "     \n",
        "    result_filtered = result[np.where(result[:, 4] > score_threshold)]\n",
        "    \n",
        "    # confidence score가 threshold 이상으로 탐지된 object에 대하여 표시한다\n",
        "    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출. \n",
        "    for i in range(len(result_filtered)):\n",
        "      # 좌상단, 우하단 좌표 추출. \n",
        "      left = int(result_filtered[i, 0])\n",
        "      top = int(result_filtered[i, 1])\n",
        "      right = int(result_filtered[i, 2])\n",
        "      bottom = int(result_filtered[i, 3])\n",
        "      caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], result_filtered[i, 4]) # Bounding Box위에 표시할 caption\n",
        "      cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=3)\n",
        "      cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)\n",
        "      if is_print:\n",
        "        print(caption)\n",
        "\n",
        "  return draw_img #  bounding box와 caption이 표시된 image를 반환한다"
      ],
      "metadata": {
        "id": "Xc0RJ3dBNhai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "input_images = [file for file in os.listdir(\"/content/drive/MyDrive/test_images\") if file.split(\".\")[1] == \"jpg\"]\n",
        "# JPG 또는 jpg파일만 inference시행\n",
        "for input_image in input_images:\n",
        "  output_image = \"/content/drive/MyDrive/Model_Weight(SMD)/ssd/result/\" + input_image[:-5] + \"_result.jpg\"\n",
        "  input_image = \"/content/drive/MyDrive/test_images/\" + input_image\n",
        "  img_arr = cv2.imread(input_image)\n",
        "  detected_img = get_detected_img(model, img_arr,  score_threshold=0.45, is_print=False)\n",
        "  cv2.imwrite(output_image, detected_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cAz1474NifG",
        "outputId": "99096bc5-725f-46c4-bbce-8e6d5a209ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mmdetection/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Video Inference\n",
        "import argparse\n",
        "import mmcv\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "for i in range(len(video_inputs)):\n",
        "  input_video = video_inputs[i]\n",
        "  output_video = video_outputs[i]\n",
        "\n",
        "  cap = mmcv.VideoReader(input_video)\n",
        "  save_name = output_video\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "  \n",
        "  out = cv2.VideoWriter(\n",
        "      save_name, fourcc, cap.fps,\n",
        "      (cap.width, cap.height)\n",
        "  )\n",
        "  frame_count = 0 # To count total frames.\n",
        "  total_fps = 0 # To get the final frames per second.\n",
        "\n",
        "  for frame in mmcv.track_iter_progress(cap):\n",
        "      # Increment frame count.\n",
        "      frame_count += 1\n",
        "      start_time = time.time()# Forward pass start time.\n",
        "      result = inference_detector(model, frame)\n",
        "      end_time = time.time() # Forward pass end time.\n",
        "      # Get the fps.\n",
        "      fps = 1 / (end_time - start_time)\n",
        "      # Add fps to total fps.\n",
        "      total_fps += fps\n",
        "      show_result = model.show_result(frame, result, score_thr=threshold)\n",
        "      # Write the FPS on the current frame.\n",
        "      cv2.putText(\n",
        "          show_result, f\"{fps:.3f} FPS\", (15, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "          1, (0, 0, 255), 2, cv2.LINE_AA\n",
        "      )\n",
        "      # mmcv.imshow(show_result, 'Result', wait_time=1)\n",
        "      out.write(show_result)\n",
        "  # Release VideoCapture()\n",
        "  out.release()\n",
        "  # Close all frames and video windows\n",
        "  cv2.destroyAllWindows()\n",
        "  # Calculate and print the average FPS\n",
        "  avg_fps = total_fps / frame_count\n",
        "  print(f\"Average FPS: {avg_fps:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El3X2xltM39f",
        "outputId": "13b4a1be-bd8a-455f-ad86-5a37f430fc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 184/184, 4.4 task/s, elapsed: 42s, ETA:     0s\n",
            "Average FPS: 25.089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Performance Evaluation***\n",
        "\n",
        "아래 셀을 수행하기 전 런타임 재시작을 하지 않으면 버그 발생 (Key error)"
      ],
      "metadata": {
        "id": "wAj5Zv1Wjkvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 아래는 런타임 다시 시작 후 실행\n",
        "from mmcv import Config\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.coco import CocoDataset\n",
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "# Dataset re-registry\n",
        "@DATASETS.register_module(force=True)\n",
        "class SMDDataset(CocoDataset):\n",
        "  CLASSES = ('Ferry','Buoy', 'Vessel/ship', 'Speed boat','Boat','Kayak','Sail boat','Swimming person','Flying bird/plane','Other')\n",
        "\n",
        "# Reset config and rebuild model\n",
        "# Modify dataset type and path.\n",
        "config_file = '/content/mmdetection/configs/ssd/ssd300_coco.py'\n",
        "checkpoint_file = '/content/drive/MyDrive/Model_Weight(SMD)/ssd/ssd_final_weight.pth'\n",
        "\n",
        "cfg = Config.fromfile(config_file)\n",
        "\n",
        "# Modify dataset type and path.\n",
        "cfg.dataset_type = 'SMDDataset'\n",
        "cfg.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "\n",
        "cfg.data.test.type = 'SMDDataset'\n",
        "cfg.data.test.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "cfg.data.test.ann_file = 'val.json'\n",
        "cfg.data.test.img_prefix = 'val'\n",
        "\n",
        "cfg.data.train.type = 'SMDDataset'\n",
        "cfg.data.train.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "cfg.data.train.ann_file = 'train.json'\n",
        "cfg.data.train.img_prefix = 'train'\n",
        "\n",
        "cfg.data.val.type = 'SMDDataset'\n",
        "cfg.data.val.data_root = '/content/drive/MyDrive/SMDDataset/35_Frame'\n",
        "cfg.data.val.ann_file = 'val.json'\n",
        "cfg.data.val.img_prefix = 'val'\n",
        "\n",
        "# Batch size (samples per GPU).\n",
        "cfg.data.samples_per_gpu = 1\n",
        "\n",
        "# Modify number of classes as per the model head.\n",
        "cfg.model.bbox_head.num_classes = 10\n",
        "\n",
        "cfg.load_from = '/content/drive/MyDrive/Model_Weight(SMD)/ssd/ssd_final_weight.pth'\n",
        "\n",
        "# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \n",
        "cfg.work_dir = './content/drive/MyDrive/Model_Weight(SMD)/ssd'\n",
        "\n",
        "cfg.evaluation.metric = 'bbox'\n",
        "cfg.evaluation.interval = 12\n",
        "cfg.evaluation.classwise = True\n",
        "cfg.checkpoint_config.interval = 12\n",
        "\n",
        "# 두번 config를 로드하면 lr_config의 policy가 사라지는 오류로 인하여 설정. \n",
        "cfg.lr_config.policy='step'\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)"
      ],
      "metadata": {
        "id": "w7g4HzChpaoo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b676459c-878d-4224-e7e7-9617a98d388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aivypAlLcoSS"
      },
      "outputs": [],
      "source": [
        "from mmdet.datasets import (build_dataloader, build_dataset,replace_ImageToTensor)\n",
        "\n",
        "# test용 Dataset과 DataLoader 생성. \n",
        "# build_dataset()호출 시 list로 감싸지 않는 것이 train용 dataset 생성시와 차이\n",
        "# train용 dataset는 list로 감싸야 하고, test용 dataset는 list로 감싸지 않는다\n",
        "dataset = build_dataset(cfg.data.test) # test dataset을 만든다\n",
        "data_loader = build_dataloader(\n",
        "        dataset,\n",
        "        # 반드시 아래 samples_per_gpu 인자값은 1로 설정\n",
        "        samples_per_gpu=cfg.data.samples_per_gpu, # 그래서 아까 config설정할 때 이 값을 1로 설정한 것이다\n",
        "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
        "        dist=False,\n",
        "        shuffle=False)\n",
        "\n",
        "# \n",
        "next(iter(data_loader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "\n",
        "checkpoint_file = '/content/drive/MyDrive/Model_Weight(SMD)/ssd/ssd_final_weight.pth' # 아까 train후 만들어진 가중치\n",
        "\n",
        "# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n",
        "model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXBv8BBSkEev",
        "outputId": "0183b75c-d9e6-46b7-cfc0-c514898eaae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from local path: /content/drive/MyDrive/Model_Weight(SMD)/ssd/ssd_final_weight.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmdet.apis import multi_gpu_test, single_gpu_test\n",
        "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
        "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "\n",
        "model_ckpt = MMDataParallel(model_ckpt, device_ids=[0]) # 병렬처리를 하기 위함\n",
        "# single_gpu_test() 를 호출하여 test데이터 세트의 interence 수행. 반드시 batch size는 1이 되어야 함. \n",
        "# 위에서 만든 /content/show_test_output 디렉토리에 interence 결과가 시각화된 이미지가 저장됨.\n",
        "# 이것도 batch_size=1이 아니면 문제가 생긴다.\n",
        "# test dataset의 결과(inference가 적용된 이미지 결과)를 저장\n",
        "outputs = single_gpu_test(model_ckpt, data_loader, True, '/content', 0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_jFNVb9kVfX",
        "outputId": "a09cdf4b-efa0-4c21-8766-6f938bd02c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 113/113, 2.3 task/s, elapsed: 50s, ETA:     0s"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation실시\n",
        "metric = dataset.evaluate(outputs, metric='bbox', classwise = True)\n",
        "print(metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtf-Eld0kd-Y",
        "outputId": "7478044b-c460-4983-ee30-c18d7815d1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            "\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.674\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.470\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.451\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.591\n",
            "\n",
            "\n",
            "+------------+-------+-----------------+-------+-------------------+-------+\n",
            "| category   | AP    | category        | AP    | category          | AP    |\n",
            "+------------+-------+-----------------+-------+-------------------+-------+\n",
            "| Ferry      | 0.322 | Buoy            | 0.551 | Vessel/ship       | 0.562 |\n",
            "| Speed boat | 0.367 | Boat            | 0.028 | Kayak             | nan   |\n",
            "| Sail boat  | 0.857 | Swimming person | nan   | Flying bird/plane | 0.454 |\n",
            "| Other      | 0.412 | None            | None  | None              | None  |\n",
            "+------------+-------+-----------------+-------+-------------------+-------+\n",
            "OrderedDict([('bbox_mAP', 0.4442), ('bbox_mAP_50', 0.6744), ('bbox_mAP_75', 0.4703), ('bbox_mAP_s', 0.2331), ('bbox_mAP_m', 0.4507), ('bbox_mAP_l', 0.5478), ('bbox_mAP_copypaste', '0.4442 0.6744 0.4703 0.2331 0.4507 0.5478')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ubTozESlaSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}