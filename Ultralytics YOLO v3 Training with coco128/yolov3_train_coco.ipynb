{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "yolov3_train_coco.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPvjfCWE2KFj"
      },
      "source": [
        "### Ultralytics Yolo v3 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "I_Ua0GO8Sa5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de3a221-61c8-46d4-d45c-3097421b1aa6"
      },
      "source": [
        "# Ultralytics YOLO V3 설치하기\n",
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!cd yolov3;pip install -qr requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 10029, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10029 (delta 3), reused 9 (delta 3), pack-reused 10017\u001b[K\n",
            "Receiving objects: 100% (10029/10029), 9.36 MiB | 20.30 MiB/s, done.\n",
            "Resolving deltas: 100% (6762/6762), done.\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 10.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 44.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 980 kB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 74.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 74.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 72.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b1xaZlnSSa53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eaa3d69-d866-4cc2-ed14-e8f15ba31848"
      },
      "source": [
        "# torch version과 GPU를 확인한다\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.12.1+cu113 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wuNsf3fL2kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f52955-25df-4e09-a4d7-5936b6789c69"
      },
      "source": [
        "# 이전 mmDetection 패키지에서는 config를 수정하고 CustomDataset을 만듦으로써 COCO Dataset을 train하였다\n",
        "# 여기 Ultralytics에서는 다음과 같이 .yaml이라는 확장자 파일이 존재한다\n",
        "# 이 yaml은 그냥 config파일이라고 생각하면 된다\n",
        "# --data coco128.yaml 의미 : data와 관련해선 coco128.yaml에 명시되어 있는 대로 학습을 진행하겠습니다\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov3\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.6.0-21-g92c3bd7 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 15.1MB/s]\n",
            "Dataset autodownload success, saved to ../datasets\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt to yolov3.pt...\n",
            "100% 119M/119M [00:14<00:00, 8.78MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.6 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 1777.11it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.9G   0.03646   0.05139   0.01218       170       640: 100% 8/8 [00:16<00:00,  2.09s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.17it/s]\n",
            "                 all        128        929      0.701      0.772       0.81      0.578\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     10.6G   0.03673   0.05762   0.01166       246       640:  25% 2/8 [00:01<00:04,  1.32it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQd5TmHMgxE"
      },
      "source": [
        "### wandb(weight and bias) 모듈을 설치\n",
        "* 먼저 Weight and Bias 웹사이트에 계정 생성 및 연계 후 train 작업이 필요할 수도 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKc9lL_oKCPJ"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2Hcsh1R5iB"
      },
      "source": [
        "%cd /content\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNIrsZHI0_tz"
      },
      "source": [
        "### Dataset Config와 Weight 파일의 상대 경로, 절대 경로\n",
        "### 어떠한 package로 프로젝트를 진행하던지 간에 중요한내용이다\n",
        "* train.py의 data option값으로 Dataset config yaml 파일을 지정할 수 있으며, 파일명만 입력할 경우는 yolov3/data 디렉토리 아래에서 해당 파일을 찾음. 절대 경로로 입력할 경우 해당 경로에서 찾음. \n",
        "* weights option의 경우 파일명만 입력할 경우 yolov3 디렉토리에서 해당 파일을 찾음. 해당 파일이 없을 경우 자동으로 해당 파일을 https://github.com/ultralytics/yolov3/releases 에서 Download 함. 절대 경로를 입력한 경우 해당 경로에서 파일을 찾되 파일이 없으면 해당 경로로 자동 Download함. \n",
        "* weights 파일은 yolov3.pt, yolov3-tiny.pt, yolov3-spp.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfxF4g_3Zh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252b3257-cb1a-45a9-9f21-688f991c86ce"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wPnWKNXMSa5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642cc7db-f50b-451c-e728-05ef44498995"
      },
      "source": [
        "# --data coco128.yaml : /content/yolov3/data 디렉토리에서 자동적으로 coco128.yaml파일을 찾아 사용한다\n",
        "# --weights yolov3.pt : /content/yolov3 디렉토리에서 자동적으로 yolov3.pt파일을 찾아 사용한다\n",
        "# 위에 pt파일이 없다면 특정 URL에서 download받도록 설정되어 있다\n",
        "# --nosave : 최종 epoch의 학습 weight만 저장한다\n",
        "# --cache : cache기능 이용하여 이미 한 번 가져온 이미지를 다시 불러올 때 빠르게 불러와 속도 향상을 도모한다\n",
        "\n",
        "!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "\n",
        "# 아래와 같이 해도 된다. --weight옵션을 ''로 하고, --cfg옵션의 인자로 yolov3.yaml이라고 하면\n",
        "# /content/yolov3/models 디렉토리에서 yolov3.yaml이라는 파일을 찾아 사용한다\n",
        "# 굳이 이렇게 하지 말고 위의 방법을 이용하면 더 좋을 것!\n",
        "\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-spp.pt --nosave --cache"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.6.0-21-g92c3bd7 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 84.3MB/s]\n",
            "Dataset autodownload success, saved to ../datasets\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt to yolov3.pt...\n",
            "100% 119M/119M [00:12<00:00, 9.79MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.6 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 2021.73it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 281.30it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:01<00:00, 121.33it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.9G   0.03646   0.05139   0.01218       170       640: 100% 8/8 [00:16<00:00,  2.03s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.17it/s]\n",
            "                 all        128        929      0.701      0.772      0.811      0.578\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     10.7G   0.03638   0.05335   0.01048       204       640: 100% 8/8 [00:06<00:00,  1.27it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.93it/s]\n",
            "                 all        128        929      0.708      0.774      0.813       0.58\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     12.1G   0.03671   0.05941   0.01124       281       640: 100% 8/8 [00:06<00:00,  1.25it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.91it/s]\n",
            "                 all        128        929      0.705      0.776      0.814      0.582\n",
            "\n",
            "3 epochs completed in 0.011 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 124.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 124.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61922845 parameters, 0 gradients, 155.9 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.18s/it]\n",
            "                 all        128        929      0.734      0.755      0.815      0.583\n",
            "              person        128        254      0.827      0.803      0.862      0.627\n",
            "             bicycle        128          6      0.529      0.568      0.586      0.386\n",
            "                 car        128         46      0.847      0.565      0.688      0.331\n",
            "          motorcycle        128          5      0.776          1      0.995      0.817\n",
            "            airplane        128          6      0.915          1      0.995      0.837\n",
            "                 bus        128          7          1      0.764      0.978      0.817\n",
            "               train        128          3      0.844          1      0.995      0.797\n",
            "               truck        128         12      0.644      0.583      0.649      0.417\n",
            "                boat        128          6        0.6      0.501      0.695      0.493\n",
            "       traffic light        128         14      0.855      0.429      0.539      0.276\n",
            "           stop sign        128          2      0.722          1      0.995      0.796\n",
            "               bench        128          9          1      0.657      0.796      0.369\n",
            "                bird        128         16      0.962          1      0.995      0.672\n",
            "                 cat        128          4      0.751          1      0.995      0.933\n",
            "                 dog        128          9      0.773          1      0.955      0.746\n",
            "               horse        128          2      0.638          1      0.995      0.623\n",
            "            elephant        128         17      0.995      0.941      0.947      0.782\n",
            "                bear        128          1      0.604          1      0.995      0.895\n",
            "               zebra        128          4      0.863          1      0.995      0.946\n",
            "             giraffe        128          9      0.962          1      0.995      0.822\n",
            "            backpack        128          6      0.874      0.667      0.714      0.486\n",
            "            umbrella        128         18      0.792      0.833      0.866      0.564\n",
            "             handbag        128         19      0.645      0.526       0.56      0.363\n",
            "                 tie        128          7      0.872      0.857      0.858      0.604\n",
            "            suitcase        128          4       0.61          1      0.995      0.672\n",
            "             frisbee        128          5      0.717        0.8       0.76       0.61\n",
            "                skis        128          1      0.672          1      0.995      0.597\n",
            "           snowboard        128          7      0.852      0.829      0.873      0.632\n",
            "         sports ball        128          6      0.765      0.833       0.78      0.559\n",
            "                kite        128         10      0.377        0.6       0.57      0.172\n",
            "        baseball bat        128          4      0.637      0.887      0.912      0.365\n",
            "      baseball glove        128          7      0.512      0.571      0.597      0.428\n",
            "          skateboard        128          5      0.632        0.8      0.803      0.427\n",
            "       tennis racket        128          7      0.776      0.714      0.718       0.36\n",
            "              bottle        128         18      0.744      0.889      0.741      0.482\n",
            "          wine glass        128         16      0.823      0.688      0.888      0.494\n",
            "                 cup        128         36      0.801      0.889      0.885       0.63\n",
            "                fork        128          6      0.566        0.5      0.596      0.418\n",
            "               knife        128         16       0.83      0.812      0.822      0.519\n",
            "               spoon        128         22      0.593        0.5      0.575      0.396\n",
            "                bowl        128         28      0.869       0.75      0.798      0.635\n",
            "              banana        128          1      0.694          1      0.995      0.895\n",
            "            sandwich        128          2          0          0      0.497      0.202\n",
            "              orange        128          4          1      0.681      0.888      0.691\n",
            "            broccoli        128         11      0.449      0.364      0.469      0.353\n",
            "              carrot        128         24      0.727      0.776      0.814      0.526\n",
            "             hot dog        128          2       0.56          1      0.828      0.828\n",
            "               pizza        128          5      0.722          1      0.962      0.689\n",
            "               donut        128         14      0.716          1      0.973      0.875\n",
            "                cake        128          4      0.714          1      0.995      0.846\n",
            "               chair        128         35      0.649      0.857      0.854      0.543\n",
            "               couch        128          6      0.982      0.833      0.899      0.583\n",
            "        potted plant        128         14      0.831      0.857       0.92      0.553\n",
            "                 bed        128          3      0.474      0.316      0.608      0.487\n",
            "        dining table        128         13      0.663      0.615      0.666        0.4\n",
            "              toilet        128          2      0.744          1      0.995      0.896\n",
            "                  tv        128          2      0.686          1      0.995      0.846\n",
            "              laptop        128          3          1          0      0.913      0.445\n",
            "               mouse        128          2      0.962        0.5      0.745       0.35\n",
            "              remote        128          8      0.856      0.625      0.713      0.582\n",
            "          cell phone        128          8      0.599        0.5      0.651      0.392\n",
            "           microwave        128          3      0.723          1      0.995      0.852\n",
            "                oven        128          5      0.556        0.6      0.499      0.379\n",
            "                sink        128          6       0.55      0.417      0.528       0.31\n",
            "        refrigerator        128          5      0.601        0.8      0.845      0.587\n",
            "                book        128         29      0.552      0.276      0.411      0.216\n",
            "               clock        128          9      0.731          1      0.975      0.807\n",
            "                vase        128          2      0.587          1      0.995      0.995\n",
            "            scissors        128          1          1          0      0.332     0.0663\n",
            "          teddy bear        128         21      0.898      0.838      0.934      0.629\n",
            "          toothbrush        128          5      0.791          1      0.995      0.754\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZSXORZdEmvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c26907-6d74-431e-8856-876fa9b166c3"
      },
      "source": [
        "!cp /content/yolov3/data/coco128.yaml /content/coco128/coco128.yaml"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/coco128/coco128.yaml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf1hUSV6Myw9"
      },
      "source": [
        "### COCO128 데이터 디렉토리를 변경후 학습 수행\n",
        "* /content/data 아래에 coco128 데이터 download 후 unzip\n",
        "* coco128 디렉토리가 변경되었으므로 coco128.yaml 데이터도 변경 적용. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz37RavwxYE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214f85d2-6548-49d8-adad-2054995e006c"
      },
      "source": [
        "# 먼저 기존의 coco128 디렉토리를 삭제해보자\n",
        "%cd /content\n",
        "!rm -rf /content/coco128"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD-azX0i2m-Y"
      },
      "source": [
        "# 다시 다운로드 받기\n",
        "# /content/data 디렉토리에 coco128.zip을 download하고 압축 해제\n",
        "!mkdir /content/data\n",
        "!wget -O /content/data/coco128.zip https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
        "!cd /content/data; unzip coco128.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "b4hTenv2Sa59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d58b366-6c1f-4b8b-b887-b48867ea2582"
      },
      "source": [
        "# Directory 구조가 바뀌었으므로 yaml파일에 존재하는 Dataset의 train/val data경로 정보도 바꾸어 주어야 한다\n",
        "!wget -O /content/data/coco128/coco128_renew.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
        "!cat /content/data/coco128/coco128_renew.yaml"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-27 16:19:46--  https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1594 (1.6K) [text/plain]\n",
            "Saving to: ‘/content/data/coco128/coco128_renew.yaml’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/data/coco1 100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-27 16:19:47 (24.6 MB/s) - ‘/content/data/coco128/coco128_renew.yaml’ saved [1594/1594]\n",
            "\n",
            "# COCO 2017 dataset http://cocodataset.org - first 128 training images\n",
            "# Train command: python train.py --data coco128.yaml\n",
            "# Default dataset location is next to YOLOv3:\n",
            "#   /parent_folder\n",
            "#     /coco128\n",
            "#     /yolov3\n",
            "\n",
            "\n",
            "# download command/URL (optional)\n",
            "#download: https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
            "\n",
            "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
            "train: /content/data/coco128/images/train2017/  # 128 images\n",
            "val: /content/data/coco128/images/train2017/  # 128 images\n",
            "\n",
            "# number of classes\n",
            "nc: 80\n",
            "\n",
            "# class names\n",
            "names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
            "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
            "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
            "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
            "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
            "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
            "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
            "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
            "         'hair drier', 'toothbrush' ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZkk2f09xWDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3501cf86-e868-4168-c448-296c9d9a9b2d"
      },
      "source": [
        "# train 실시하기\n",
        "!cd /content/yolov3; python train.py --img 640 --batch 16 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=/content/data/coco128/coco128_renew.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.6.0-21-g92c3bd7 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.6 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 2079.80it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 297.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:01<00:00, 117.04it/s]\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.9G   0.03646   0.05139   0.01218       170       640: 100% 8/8 [00:10<00:00,  1.27s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.88it/s]\n",
            "                 all        128        929      0.701      0.772      0.811      0.579\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     10.7G   0.03638   0.05336   0.01048       204       640: 100% 8/8 [00:06<00:00,  1.31it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.01it/s]\n",
            "                 all        128        929      0.708      0.774      0.813       0.58\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     12.1G   0.03671   0.05943   0.01124       281       640: 100% 8/8 [00:06<00:00,  1.31it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.01it/s]\n",
            "                 all        128        929      0.705      0.776      0.814      0.583\n",
            "\n",
            "3 epochs completed in 0.009 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 124.4MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 124.4MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61922845 parameters, 0 gradients, 155.9 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.08s/it]\n",
            "                 all        128        929      0.734      0.755      0.815      0.582\n",
            "              person        128        254       0.83      0.803      0.863      0.627\n",
            "             bicycle        128          6      0.532      0.574      0.586      0.386\n",
            "                 car        128         46      0.848      0.565      0.688      0.331\n",
            "          motorcycle        128          5      0.776          1      0.995      0.817\n",
            "            airplane        128          6      0.915          1      0.995      0.837\n",
            "                 bus        128          7          1      0.764      0.978      0.824\n",
            "               train        128          3      0.844          1      0.995      0.797\n",
            "               truck        128         12      0.644      0.583      0.649      0.417\n",
            "                boat        128          6        0.6      0.501      0.695      0.468\n",
            "       traffic light        128         14      0.854      0.429      0.539      0.276\n",
            "           stop sign        128          2      0.723          1      0.995      0.796\n",
            "               bench        128          9          1      0.657      0.794      0.368\n",
            "                bird        128         16      0.962          1      0.995      0.672\n",
            "                 cat        128          4      0.751          1      0.995      0.933\n",
            "                 dog        128          9      0.773          1      0.955      0.746\n",
            "               horse        128          2      0.637          1      0.995      0.623\n",
            "            elephant        128         17      0.995      0.941      0.947      0.782\n",
            "                bear        128          1      0.604          1      0.995      0.895\n",
            "               zebra        128          4      0.863          1      0.995      0.946\n",
            "             giraffe        128          9      0.962          1      0.995      0.822\n",
            "            backpack        128          6      0.873      0.667      0.714      0.486\n",
            "            umbrella        128         18      0.792      0.833      0.866      0.564\n",
            "             handbag        128         19      0.644      0.526      0.564      0.364\n",
            "                 tie        128          7      0.872      0.857      0.858      0.604\n",
            "            suitcase        128          4       0.61          1      0.995      0.672\n",
            "             frisbee        128          5      0.717        0.8       0.76       0.61\n",
            "                skis        128          1      0.672          1      0.995      0.597\n",
            "           snowboard        128          7      0.852      0.829      0.873      0.632\n",
            "         sports ball        128          6      0.766      0.833       0.78      0.559\n",
            "                kite        128         10      0.376        0.6       0.57      0.172\n",
            "        baseball bat        128          4      0.637      0.888      0.912      0.365\n",
            "      baseball glove        128          7      0.512      0.571      0.597      0.417\n",
            "          skateboard        128          5      0.625        0.8      0.803      0.427\n",
            "       tennis racket        128          7      0.776      0.714      0.718       0.36\n",
            "              bottle        128         18      0.744      0.889      0.741      0.482\n",
            "          wine glass        128         16      0.826      0.688      0.888      0.494\n",
            "                 cup        128         36      0.801      0.889      0.884      0.627\n",
            "                fork        128          6      0.565        0.5      0.596       0.41\n",
            "               knife        128         16      0.829      0.812      0.822      0.514\n",
            "               spoon        128         22      0.593        0.5      0.583      0.402\n",
            "                bowl        128         28      0.869       0.75      0.798      0.635\n",
            "              banana        128          1      0.694          1      0.995      0.895\n",
            "            sandwich        128          2          0          0      0.497      0.202\n",
            "              orange        128          4          1      0.679      0.888      0.691\n",
            "            broccoli        128         11      0.449      0.364      0.469      0.353\n",
            "              carrot        128         24      0.727      0.777      0.814      0.526\n",
            "             hot dog        128          2       0.56          1      0.828      0.828\n",
            "               pizza        128          5      0.722          1      0.962      0.689\n",
            "               donut        128         14      0.716          1      0.973      0.878\n",
            "                cake        128          4      0.714          1      0.995      0.846\n",
            "               chair        128         35      0.649      0.857      0.854       0.54\n",
            "               couch        128          6      0.983      0.833      0.899      0.583\n",
            "        potted plant        128         14      0.831      0.857       0.92      0.566\n",
            "                 bed        128          3      0.474      0.316      0.608      0.487\n",
            "        dining table        128         13      0.663      0.615      0.666        0.4\n",
            "              toilet        128          2      0.744          1      0.995      0.896\n",
            "                  tv        128          2      0.686          1      0.995      0.846\n",
            "              laptop        128          3          1          0      0.913      0.445\n",
            "               mouse        128          2      0.962        0.5      0.745       0.35\n",
            "              remote        128          8      0.856      0.625      0.713      0.582\n",
            "          cell phone        128          8        0.6        0.5      0.651      0.392\n",
            "           microwave        128          3      0.723          1      0.995      0.852\n",
            "                oven        128          5      0.558        0.6      0.499      0.379\n",
            "                sink        128          6       0.55      0.416      0.528       0.31\n",
            "        refrigerator        128          5      0.601        0.8      0.845      0.587\n",
            "                book        128         29      0.553      0.276      0.411      0.216\n",
            "               clock        128          9       0.73          1      0.975      0.807\n",
            "                vase        128          2      0.587          1      0.995      0.995\n",
            "            scissors        128          1          1          0      0.332     0.0663\n",
            "          teddy bear        128         21      0.898      0.838      0.934      0.629\n",
            "          toothbrush        128          5      0.791          1      0.995      0.754\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### yaml파일에서 중요한 점\n",
        "* train 경로가 이렇게 되어 있을 것이다\n",
        "* /content/data/coco128/images/train2017\n",
        "* 그러면 train이미지의 annotation파일은 다음에서 자동으로 찾는다\n",
        "* /content/data/coco128/labels/train2017\n",
        "* 위 images디렉토리가 아닌 labels 디렉토리에서 찾는다.이와 같은 명명규칙을 모르면 debugging이 매우 불편해진다"
      ],
      "metadata": {
        "id": "HXzseIOrHdhA"
      }
    }
  ]
}