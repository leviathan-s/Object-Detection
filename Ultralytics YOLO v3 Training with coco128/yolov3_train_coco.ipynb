{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "yolov3_train_coco.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPvjfCWE2KFj"
      },
      "source": [
        "### Ultralytics Yolo v3 ÏÑ§Ïπò"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "I_Ua0GO8Sa5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de3a221-61c8-46d4-d45c-3097421b1aa6"
      },
      "source": [
        "# Ultralytics YOLO V3 ÏÑ§ÏπòÌïòÍ∏∞\n",
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!cd yolov3;pip install -qr requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 10029, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10029 (delta 3), reused 9 (delta 3), pack-reused 10017\u001b[K\n",
            "Receiving objects: 100% (10029/10029), 9.36 MiB | 20.30 MiB/s, done.\n",
            "Resolving deltas: 100% (6762/6762), done.\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.8 MB 10.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 44.3 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 181 kB 47.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63 kB 980 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 70.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 74.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 70.4 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 74.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 156 kB 72.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b1xaZlnSSa53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eaa3d69-d866-4cc2-ed14-e8f15ba31848"
      },
      "source": [
        "# torch versionÍ≥º GPUÎ•º ÌôïÏù∏ÌïúÎã§\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.12.1+cu113 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wuNsf3fL2kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f52955-25df-4e09-a4d7-5936b6789c69"
      },
      "source": [
        "# Ïù¥Ï†Ñ mmDetection Ìå®ÌÇ§ÏßÄÏóêÏÑúÎäî configÎ•º ÏàòÏ†ïÌïòÍ≥† CustomDatasetÏùÑ ÎßåÎì¶ÏúºÎ°úÏç® COCO DatasetÏùÑ trainÌïòÏòÄÎã§\n",
        "# Ïó¨Í∏∞ UltralyticsÏóêÏÑúÎäî Îã§ÏùåÍ≥º Í∞ôÏù¥ .yamlÏù¥ÎùºÎäî ÌôïÏû•Ïûê ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïúÎã§\n",
        "# Ïù¥ yamlÏùÄ Í∑∏ÎÉ• configÌååÏùºÏù¥ÎùºÍ≥† ÏÉùÍ∞ÅÌïòÎ©¥ ÎêúÎã§\n",
        "# --data coco128.yaml ÏùòÎØ∏ : dataÏôÄ Í¥ÄÎ†®Ìï¥ÏÑ† coco128.yamlÏóê Î™ÖÏãúÎêòÏñ¥ ÏûàÎäî ÎåÄÎ°ú ÌïôÏäµÏùÑ ÏßÑÌñâÌïòÍ≤†ÏäµÎãàÎã§\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov3\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ‚úÖ\n",
            "YOLOv3 üöÄ v9.6.0-21-g92c3bd7 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 üöÄ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 15.1MB/s]\n",
            "Dataset autodownload success, saved to ../datasets\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt to yolov3.pt...\n",
            "100% 119M/119M [00:14<00:00, 8.78MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.6 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 1777.11it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.9G   0.03646   0.05139   0.01218       170       640: 100% 8/8 [00:16<00:00,  2.09s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.17it/s]\n",
            "                 all        128        929      0.701      0.772       0.81      0.578\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     10.6G   0.03673   0.05762   0.01166       246       640:  25% 2/8 [00:01<00:04,  1.32it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQd5TmHMgxE"
      },
      "source": [
        "### wandb(weight and bias) Î™®ÎìàÏùÑ ÏÑ§Ïπò\n",
        "* Î®ºÏ†Ä Weight and Bias ÏõπÏÇ¨Ïù¥Ìä∏Ïóê Í≥ÑÏ†ï ÏÉùÏÑ± Î∞è Ïó∞Í≥Ñ ÌõÑ train ÏûëÏóÖÏù¥ ÌïÑÏöîÌï† ÏàòÎèÑ ÏûàÏùå."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKc9lL_oKCPJ"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2Hcsh1R5iB"
      },
      "source": [
        "%cd /content\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNIrsZHI0_tz"
      },
      "source": [
        "### Dataset ConfigÏôÄ Weight ÌååÏùºÏùò ÏÉÅÎåÄ Í≤ΩÎ°ú, Ï†àÎåÄ Í≤ΩÎ°ú\n",
        "### Ïñ¥Îñ†Ìïú packageÎ°ú ÌîÑÎ°úÏ†ùÌä∏Î•º ÏßÑÌñâÌïòÎçòÏßÄ Í∞ÑÏóê Ï§ëÏöîÌïúÎÇ¥Ïö©Ïù¥Îã§\n",
        "* train.pyÏùò data optionÍ∞íÏúºÎ°ú Dataset config yaml ÌååÏùºÏùÑ ÏßÄÏ†ïÌï† Ïàò ÏûàÏúºÎ©∞, ÌååÏùºÎ™ÖÎßå ÏûÖÎ†•Ìï† Í≤ΩÏö∞Îäî yolov3/data ÎîîÎ†âÌÜ†Î¶¨ ÏïÑÎûòÏóêÏÑú Ìï¥Îãπ ÌååÏùºÏùÑ Ï∞æÏùå. Ï†àÎåÄ Í≤ΩÎ°úÎ°ú ÏûÖÎ†•Ìï† Í≤ΩÏö∞ Ìï¥Îãπ Í≤ΩÎ°úÏóêÏÑú Ï∞æÏùå. \n",
        "* weights optionÏùò Í≤ΩÏö∞ ÌååÏùºÎ™ÖÎßå ÏûÖÎ†•Ìï† Í≤ΩÏö∞ yolov3 ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú Ìï¥Îãπ ÌååÏùºÏùÑ Ï∞æÏùå. Ìï¥Îãπ ÌååÏùºÏù¥ ÏóÜÏùÑ Í≤ΩÏö∞ ÏûêÎèôÏúºÎ°ú Ìï¥Îãπ ÌååÏùºÏùÑ https://github.com/ultralytics/yolov3/releases ÏóêÏÑú Download Ìï®. Ï†àÎåÄ Í≤ΩÎ°úÎ•º ÏûÖÎ†•Ìïú Í≤ΩÏö∞ Ìï¥Îãπ Í≤ΩÎ°úÏóêÏÑú ÌååÏùºÏùÑ Ï∞æÎêò ÌååÏùºÏù¥ ÏóÜÏúºÎ©¥ Ìï¥Îãπ Í≤ΩÎ°úÎ°ú ÏûêÎèô DownloadÌï®. \n",
        "* weights ÌååÏùºÏùÄ yolov3.pt, yolov3-tiny.pt, yolov3-spp.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfxF4g_3Zh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252b3257-cb1a-45a9-9f21-688f991c86ce"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wPnWKNXMSa5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642cc7db-f50b-451c-e728-05ef44498995"
      },
      "source": [
        "# --data coco128.yaml : /content/yolov3/data ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú ÏûêÎèôÏ†ÅÏúºÎ°ú coco128.yamlÌååÏùºÏùÑ Ï∞æÏïÑ ÏÇ¨Ïö©ÌïúÎã§\n",
        "# --weights yolov3.pt : /content/yolov3 ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú ÏûêÎèôÏ†ÅÏúºÎ°ú yolov3.ptÌååÏùºÏùÑ Ï∞æÏïÑ ÏÇ¨Ïö©ÌïúÎã§\n",
        "# ÏúÑÏóê ptÌååÏùºÏù¥ ÏóÜÎã§Î©¥ ÌäπÏ†ï URLÏóêÏÑú downloadÎ∞õÎèÑÎ°ù ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÎã§\n",
        "# --nosave : ÏµúÏ¢Ö epochÏùò ÌïôÏäµ weightÎßå Ï†ÄÏû•ÌïúÎã§\n",
        "# --cache : cacheÍ∏∞Îä• Ïù¥Ïö©ÌïòÏó¨ Ïù¥ÎØ∏ Ìïú Î≤à Í∞ÄÏ†∏Ïò® Ïù¥ÎØ∏ÏßÄÎ•º Îã§Ïãú Î∂àÎü¨Ïò¨ Îïå Îπ†Î•¥Í≤å Î∂àÎü¨ÏôÄ ÏÜçÎèÑ Ìñ•ÏÉÅÏùÑ ÎèÑÎ™®ÌïúÎã§\n",
        "\n",
        "!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "\n",
        "# ÏïÑÎûòÏôÄ Í∞ôÏù¥ Ìï¥ÎèÑ ÎêúÎã§. --weightÏòµÏÖòÏùÑ ''Î°ú ÌïòÍ≥†, --cfgÏòµÏÖòÏùò Ïù∏ÏûêÎ°ú yolov3.yamlÏù¥ÎùºÍ≥† ÌïòÎ©¥\n",
        "# /content/yolov3/models ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú yolov3.yamlÏù¥ÎùºÎäî ÌååÏùºÏùÑ Ï∞æÏïÑ ÏÇ¨Ïö©ÌïúÎã§\n",
        "# Íµ≥Ïù¥ Ïù¥Î†áÍ≤å ÌïòÏßÄ ÎßêÍ≥† ÏúÑÏùò Î∞©Î≤ïÏùÑ Ïù¥Ïö©ÌïòÎ©¥ Îçî Ï¢ãÏùÑ Í≤É!\n",
        "\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-spp.pt --nosave --cache"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ‚úÖ\n",
            "YOLOv3 üöÄ v9.6.0-21-g92c3bd7 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 üöÄ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 84.3MB/s]\n",
            "Dataset autodownload success, saved to ../datasets\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt to yolov3.pt...\n",
            "100% 119M/119M [00:12<00:00, 9.79MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.6 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 2021.73it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 281.30it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:01<00:00, 121.33it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.9G   0.03646   0.05139   0.01218       170       640: 100% 8/8 [00:16<00:00,  2.03s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.17it/s]\n",
            "                 all        128        929      0.701      0.772      0.811      0.578\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     10.7G   0.03638   0.05335   0.01048       204       640: 100% 8/8 [00:06<00:00,  1.27it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.93it/s]\n",
            "                 all        128        929      0.708      0.774      0.813       0.58\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     12.1G   0.03671   0.05941   0.01124       281       640: 100% 8/8 [00:06<00:00,  1.25it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.91it/s]\n",
            "                 all        128        929      0.705      0.776      0.814      0.582\n",
            "\n",
            "3 epochs completed in 0.011 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 124.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 124.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61922845 parameters, 0 gradients, 155.9 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.18s/it]\n",
            "                 all        128        929      0.734      0.755      0.815      0.583\n",
            "              person        128        254      0.827      0.803      0.862      0.627\n",
            "             bicycle        128          6      0.529      0.568      0.586      0.386\n",
            "                 car        128         46      0.847      0.565      0.688      0.331\n",
            "          motorcycle        128          5      0.776          1      0.995      0.817\n",
            "            airplane        128          6      0.915          1      0.995      0.837\n",
            "                 bus        128          7          1      0.764      0.978      0.817\n",
            "               train        128          3      0.844          1      0.995      0.797\n",
            "               truck        128         12      0.644      0.583      0.649      0.417\n",
            "                boat        128          6        0.6      0.501      0.695      0.493\n",
            "       traffic light        128         14      0.855      0.429      0.539      0.276\n",
            "           stop sign        128          2      0.722          1      0.995      0.796\n",
            "               bench        128          9          1      0.657      0.796      0.369\n",
            "                bird        128         16      0.962          1      0.995      0.672\n",
            "                 cat        128          4      0.751          1      0.995      0.933\n",
            "                 dog        128          9      0.773          1      0.955      0.746\n",
            "               horse        128          2      0.638          1      0.995      0.623\n",
            "            elephant        128         17      0.995      0.941      0.947      0.782\n",
            "                bear        128          1      0.604          1      0.995      0.895\n",
            "               zebra        128          4      0.863          1      0.995      0.946\n",
            "             giraffe        128          9      0.962          1      0.995      0.822\n",
            "            backpack        128          6      0.874      0.667      0.714      0.486\n",
            "            umbrella        128         18      0.792      0.833      0.866      0.564\n",
            "             handbag        128         19      0.645      0.526       0.56      0.363\n",
            "                 tie        128          7      0.872      0.857      0.858      0.604\n",
            "            suitcase        128          4       0.61          1      0.995      0.672\n",
            "             frisbee        128          5      0.717        0.8       0.76       0.61\n",
            "                skis        128          1      0.672          1      0.995      0.597\n",
            "           snowboard        128          7      0.852      0.829      0.873      0.632\n",
            "         sports ball        128          6      0.765      0.833       0.78      0.559\n",
            "                kite        128         10      0.377        0.6       0.57      0.172\n",
            "        baseball bat        128          4      0.637      0.887      0.912      0.365\n",
            "      baseball glove        128          7      0.512      0.571      0.597      0.428\n",
            "          skateboard        128          5      0.632        0.8      0.803      0.427\n",
            "       tennis racket        128          7      0.776      0.714      0.718       0.36\n",
            "              bottle        128         18      0.744      0.889      0.741      0.482\n",
            "          wine glass        128         16      0.823      0.688      0.888      0.494\n",
            "                 cup        128         36      0.801      0.889      0.885       0.63\n",
            "                fork        128          6      0.566        0.5      0.596      0.418\n",
            "               knife        128         16       0.83      0.812      0.822      0.519\n",
            "               spoon        128         22      0.593        0.5      0.575      0.396\n",
            "                bowl        128         28      0.869       0.75      0.798      0.635\n",
            "              banana        128          1      0.694          1      0.995      0.895\n",
            "            sandwich        128          2          0          0      0.497      0.202\n",
            "              orange        128          4          1      0.681      0.888      0.691\n",
            "            broccoli        128         11      0.449      0.364      0.469      0.353\n",
            "              carrot        128         24      0.727      0.776      0.814      0.526\n",
            "             hot dog        128          2       0.56          1      0.828      0.828\n",
            "               pizza        128          5      0.722          1      0.962      0.689\n",
            "               donut        128         14      0.716          1      0.973      0.875\n",
            "                cake        128          4      0.714          1      0.995      0.846\n",
            "               chair        128         35      0.649      0.857      0.854      0.543\n",
            "               couch        128          6      0.982      0.833      0.899      0.583\n",
            "        potted plant        128         14      0.831      0.857       0.92      0.553\n",
            "                 bed        128          3      0.474      0.316      0.608      0.487\n",
            "        dining table        128         13      0.663      0.615      0.666        0.4\n",
            "              toilet        128          2      0.744          1      0.995      0.896\n",
            "                  tv        128          2      0.686          1      0.995      0.846\n",
            "              laptop        128          3          1          0      0.913      0.445\n",
            "               mouse        128          2      0.962        0.5      0.745       0.35\n",
            "              remote        128          8      0.856      0.625      0.713      0.582\n",
            "          cell phone        128          8      0.599        0.5      0.651      0.392\n",
            "           microwave        128          3      0.723          1      0.995      0.852\n",
            "                oven        128          5      0.556        0.6      0.499      0.379\n",
            "                sink        128          6       0.55      0.417      0.528       0.31\n",
            "        refrigerator        128          5      0.601        0.8      0.845      0.587\n",
            "                book        128         29      0.552      0.276      0.411      0.216\n",
            "               clock        128          9      0.731          1      0.975      0.807\n",
            "                vase        128          2      0.587          1      0.995      0.995\n",
            "            scissors        128          1          1          0      0.332     0.0663\n",
            "          teddy bear        128         21      0.898      0.838      0.934      0.629\n",
            "          toothbrush        128          5      0.791          1      0.995      0.754\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZSXORZdEmvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c26907-6d74-431e-8856-876fa9b166c3"
      },
      "source": [
        "!cp /content/yolov3/data/coco128.yaml /content/coco128/coco128.yaml"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/coco128/coco128.yaml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf1hUSV6Myw9"
      },
      "source": [
        "### COCO128 Îç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÜ†Î¶¨Î•º Î≥ÄÍ≤ΩÌõÑ ÌïôÏäµ ÏàòÌñâ\n",
        "* /content/data ÏïÑÎûòÏóê coco128 Îç∞Ïù¥ÌÑ∞ download ÌõÑ unzip\n",
        "* coco128 ÎîîÎ†âÌÜ†Î¶¨Í∞Ä Î≥ÄÍ≤ΩÎêòÏóàÏúºÎØÄÎ°ú coco128.yaml Îç∞Ïù¥ÌÑ∞ÎèÑ Î≥ÄÍ≤Ω Ï†ÅÏö©. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz37RavwxYE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214f85d2-6548-49d8-adad-2054995e006c"
      },
      "source": [
        "# Î®ºÏ†Ä Í∏∞Ï°¥Ïùò coco128 ÎîîÎ†âÌÜ†Î¶¨Î•º ÏÇ≠Ï†úÌï¥Î≥¥Ïûê\n",
        "%cd /content\n",
        "!rm -rf /content/coco128"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD-azX0i2m-Y"
      },
      "source": [
        "# Îã§Ïãú Îã§Ïö¥Î°úÎìú Î∞õÍ∏∞\n",
        "# /content/data ÎîîÎ†âÌÜ†Î¶¨Ïóê coco128.zipÏùÑ downloadÌïòÍ≥† ÏïïÏ∂ï Ìï¥Ï†ú\n",
        "!mkdir /content/data\n",
        "!wget -O /content/data/coco128.zip https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
        "!cd /content/data; unzip coco128.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "b4hTenv2Sa59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d58b366-6c1f-4b8b-b887-b48867ea2582"
      },
      "source": [
        "# Directory Íµ¨Ï°∞Í∞Ä Î∞îÎÄåÏóàÏúºÎØÄÎ°ú yamlÌååÏùºÏóê Ï°¥Ïû¨ÌïòÎäî DatasetÏùò train/val dataÍ≤ΩÎ°ú Ï†ïÎ≥¥ÎèÑ Î∞îÍæ∏Ïñ¥ Ï£ºÏñ¥Ïïº ÌïúÎã§\n",
        "!wget -O /content/data/coco128/coco128_renew.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
        "!cat /content/data/coco128/coco128_renew.yaml"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-27 16:19:46--  https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1594 (1.6K) [text/plain]\n",
            "Saving to: ‚Äò/content/data/coco128/coco128_renew.yaml‚Äô\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/data/coco1 100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-27 16:19:47 (24.6 MB/s) - ‚Äò/content/data/coco128/coco128_renew.yaml‚Äô saved [1594/1594]\n",
            "\n",
            "# COCO 2017 dataset http://cocodataset.org - first 128 training images\n",
            "# Train command: python train.py --data coco128.yaml\n",
            "# Default dataset location is next to YOLOv3:\n",
            "#   /parent_folder\n",
            "#     /coco128\n",
            "#     /yolov3\n",
            "\n",
            "\n",
            "# download command/URL (optional)\n",
            "#download: https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
            "\n",
            "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
            "train: /content/data/coco128/images/train2017/  # 128 images\n",
            "val: /content/data/coco128/images/train2017/  # 128 images\n",
            "\n",
            "# number of classes\n",
            "nc: 80\n",
            "\n",
            "# class names\n",
            "names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
            "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
            "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
            "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
            "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
            "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
            "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
            "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
            "         'hair drier', 'toothbrush' ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZkk2f09xWDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3501cf86-e868-4168-c448-296c9d9a9b2d"
      },
      "source": [
        "# train Ïã§ÏãúÌïòÍ∏∞\n",
        "!cd /content/yolov3; python train.py --img 640 --batch 16 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=/content/data/coco128/coco128_renew.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ‚úÖ\n",
            "YOLOv3 üöÄ v9.6.0-21-g92c3bd7 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 üöÄ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.6 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 2079.80it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 297.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:01<00:00, 117.04it/s]\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.9G   0.03646   0.05139   0.01218       170       640: 100% 8/8 [00:10<00:00,  1.27s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.88it/s]\n",
            "                 all        128        929      0.701      0.772      0.811      0.579\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     10.7G   0.03638   0.05336   0.01048       204       640: 100% 8/8 [00:06<00:00,  1.31it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.01it/s]\n",
            "                 all        128        929      0.708      0.774      0.813       0.58\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     12.1G   0.03671   0.05943   0.01124       281       640: 100% 8/8 [00:06<00:00,  1.31it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.01it/s]\n",
            "                 all        128        929      0.705      0.776      0.814      0.583\n",
            "\n",
            "3 epochs completed in 0.009 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 124.4MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 124.4MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61922845 parameters, 0 gradients, 155.9 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.08s/it]\n",
            "                 all        128        929      0.734      0.755      0.815      0.582\n",
            "              person        128        254       0.83      0.803      0.863      0.627\n",
            "             bicycle        128          6      0.532      0.574      0.586      0.386\n",
            "                 car        128         46      0.848      0.565      0.688      0.331\n",
            "          motorcycle        128          5      0.776          1      0.995      0.817\n",
            "            airplane        128          6      0.915          1      0.995      0.837\n",
            "                 bus        128          7          1      0.764      0.978      0.824\n",
            "               train        128          3      0.844          1      0.995      0.797\n",
            "               truck        128         12      0.644      0.583      0.649      0.417\n",
            "                boat        128          6        0.6      0.501      0.695      0.468\n",
            "       traffic light        128         14      0.854      0.429      0.539      0.276\n",
            "           stop sign        128          2      0.723          1      0.995      0.796\n",
            "               bench        128          9          1      0.657      0.794      0.368\n",
            "                bird        128         16      0.962          1      0.995      0.672\n",
            "                 cat        128          4      0.751          1      0.995      0.933\n",
            "                 dog        128          9      0.773          1      0.955      0.746\n",
            "               horse        128          2      0.637          1      0.995      0.623\n",
            "            elephant        128         17      0.995      0.941      0.947      0.782\n",
            "                bear        128          1      0.604          1      0.995      0.895\n",
            "               zebra        128          4      0.863          1      0.995      0.946\n",
            "             giraffe        128          9      0.962          1      0.995      0.822\n",
            "            backpack        128          6      0.873      0.667      0.714      0.486\n",
            "            umbrella        128         18      0.792      0.833      0.866      0.564\n",
            "             handbag        128         19      0.644      0.526      0.564      0.364\n",
            "                 tie        128          7      0.872      0.857      0.858      0.604\n",
            "            suitcase        128          4       0.61          1      0.995      0.672\n",
            "             frisbee        128          5      0.717        0.8       0.76       0.61\n",
            "                skis        128          1      0.672          1      0.995      0.597\n",
            "           snowboard        128          7      0.852      0.829      0.873      0.632\n",
            "         sports ball        128          6      0.766      0.833       0.78      0.559\n",
            "                kite        128         10      0.376        0.6       0.57      0.172\n",
            "        baseball bat        128          4      0.637      0.888      0.912      0.365\n",
            "      baseball glove        128          7      0.512      0.571      0.597      0.417\n",
            "          skateboard        128          5      0.625        0.8      0.803      0.427\n",
            "       tennis racket        128          7      0.776      0.714      0.718       0.36\n",
            "              bottle        128         18      0.744      0.889      0.741      0.482\n",
            "          wine glass        128         16      0.826      0.688      0.888      0.494\n",
            "                 cup        128         36      0.801      0.889      0.884      0.627\n",
            "                fork        128          6      0.565        0.5      0.596       0.41\n",
            "               knife        128         16      0.829      0.812      0.822      0.514\n",
            "               spoon        128         22      0.593        0.5      0.583      0.402\n",
            "                bowl        128         28      0.869       0.75      0.798      0.635\n",
            "              banana        128          1      0.694          1      0.995      0.895\n",
            "            sandwich        128          2          0          0      0.497      0.202\n",
            "              orange        128          4          1      0.679      0.888      0.691\n",
            "            broccoli        128         11      0.449      0.364      0.469      0.353\n",
            "              carrot        128         24      0.727      0.777      0.814      0.526\n",
            "             hot dog        128          2       0.56          1      0.828      0.828\n",
            "               pizza        128          5      0.722          1      0.962      0.689\n",
            "               donut        128         14      0.716          1      0.973      0.878\n",
            "                cake        128          4      0.714          1      0.995      0.846\n",
            "               chair        128         35      0.649      0.857      0.854       0.54\n",
            "               couch        128          6      0.983      0.833      0.899      0.583\n",
            "        potted plant        128         14      0.831      0.857       0.92      0.566\n",
            "                 bed        128          3      0.474      0.316      0.608      0.487\n",
            "        dining table        128         13      0.663      0.615      0.666        0.4\n",
            "              toilet        128          2      0.744          1      0.995      0.896\n",
            "                  tv        128          2      0.686          1      0.995      0.846\n",
            "              laptop        128          3          1          0      0.913      0.445\n",
            "               mouse        128          2      0.962        0.5      0.745       0.35\n",
            "              remote        128          8      0.856      0.625      0.713      0.582\n",
            "          cell phone        128          8        0.6        0.5      0.651      0.392\n",
            "           microwave        128          3      0.723          1      0.995      0.852\n",
            "                oven        128          5      0.558        0.6      0.499      0.379\n",
            "                sink        128          6       0.55      0.416      0.528       0.31\n",
            "        refrigerator        128          5      0.601        0.8      0.845      0.587\n",
            "                book        128         29      0.553      0.276      0.411      0.216\n",
            "               clock        128          9       0.73          1      0.975      0.807\n",
            "                vase        128          2      0.587          1      0.995      0.995\n",
            "            scissors        128          1          1          0      0.332     0.0663\n",
            "          teddy bear        128         21      0.898      0.838      0.934      0.629\n",
            "          toothbrush        128          5      0.791          1      0.995      0.754\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### yamlÌååÏùºÏóêÏÑú Ï§ëÏöîÌïú Ï†ê\n",
        "* train Í≤ΩÎ°úÍ∞Ä Ïù¥Î†áÍ≤å ÎêòÏñ¥ ÏûàÏùÑ Í≤ÉÏù¥Îã§\n",
        "* /content/data/coco128/images/train2017\n",
        "* Í∑∏Îü¨Î©¥ trainÏù¥ÎØ∏ÏßÄÏùò annotationÌååÏùºÏùÄ Îã§ÏùåÏóêÏÑú ÏûêÎèôÏúºÎ°ú Ï∞æÎäîÎã§\n",
        "* /content/data/coco128/labels/train2017\n",
        "* ÏúÑ imagesÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏïÑÎãå labels ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú Ï∞æÎäîÎã§.Ïù¥ÏôÄ Í∞ôÏùÄ Î™ÖÎ™ÖÍ∑úÏπôÏùÑ Î™®Î•¥Î©¥ debuggingÏù¥ Îß§Ïö∞ Î∂àÌé∏Ìï¥ÏßÑÎã§"
      ],
      "metadata": {
        "id": "HXzseIOrHdhA"
      }
    }
  ]
}